modules:
  asr: # 自动语音识别 (ASR) 模块
    enabled: true # 是否启用此模块
    module_category: "asr" # 模块类别，用于工厂模式查找对应的适配器工厂
    enable_module: "funasr_sensevoice" # 或者 "openai"，根据需要选择
    adapter_type: "funasr_sensevoice"
    config: # 此模块的特定配置
      funasr_sensevoice:
        model_dir: "models/asr/SenseVoiceSmall" # ASR 模型文件所在的目录路径
                                               # 请确保此路径相对于项目根目录是正确的
        device: "cpu" # 指定运行模型的设备 ("cpu" 或 "cuda" 如果GPU可用且已配置)
        sample_rate: 16000 # ASR 期望的输入音频采样率 (例如 16000 Hz)
        channels: 1 # ASR 期望的输入音频通道数 (例如 1 代表单声道)
        sample_width: 2 # 每个音频样本的字节数 (例如 2 代表 16-bit PCM 音频)
        language: "zh" # 主要识别的语言代码 (例如 "zh", "en", "auto" 如果适配器支持自动检测)
        # output_dir: "tmp/asr_intermediate_files" # 可选: 如果适配器支持，可以指定保存中间结果的目录

  llm: # 大语言模型 (LLM) 模块
    enabled: true # 是否启用此模块
    module_category: "llm" # 模块类别
    adapter_type: "langchain" # LLM 适配器的类型，例如 "langchain", "direct_openai"
                             # 需要与 `llm_factory.LLM_ADAPTER_REGISTRY` 中的键匹配
    
    # 新增: enable_module 用于指定当前要激活哪个提供商的配置
    # 这个值应该是下面 'config' 块中某个提供商配置的键名 (例如 "openai" 或 "deepseek")
    enable_module: "deepseek" # 或者 "openai"，根据需要选择

    system_prompt: "你是一个非常乐于助人的AI智能助手，请用友善和专业的语气回答问题。" # 全局系统提示，可被特定提供商配置覆盖

    config: # 包含所有受支持的 LLM 提供商的配置详情
            # LangchainLLMAdapter 会根据上面的 'enable_module' 字段选择其中一个使用
      openai: # OpenAI 提供商的配置
        model_name: "gpt-3.5-turbo" # OpenAI 的模型名称
        api_key_env_var: "OPENAI_API_KEY" # 存储 OpenAI API Key 的环境变量名称
                                          # 运行时框架会从该环境变量读取密钥
        # api_key: "sk-YOUR_OPENAI_KEY_HERE" # 或者直接在此处填写API Key (不推荐)
        temperature: 0.7 # 控制生成文本的随机性，值越高越随机
        # system_prompt: "针对OpenAI的特定系统提示" # 可选：覆盖全局 system_prompt

      deepseek: # DeepSeek 提供商的配置
        model_name: "deepseek-chat" # DeepSeek 的模型名称
        api_key_env_var: "DEEPSEEK_API_KEY" # 存储 DeepSeek API Key 的环境变量名称
        api_key: "sk-212a7abe411e404c81045233ec24879d" # 或者直接填写 (不推荐)
        temperature: 0.65 # DeepSeek 的温度参数
        # system_prompt: "针对DeepSeek的特定系统提示" # 可选

  tts: # 文本轉語音 (TTS) 模塊的頂層配置
    enabled: true               # 是否啟用此 TTS 模塊
    module_category: "tts"      # 模塊類別，用於工廠模式
    adapter_type: "edge_tts"    # 指定要使用的 TTS 適配器類型
    save_generated_audio: true
    audio_save_path: "outputs/tts_audio/"
    config:
      edge_tts:
        voice: "zh-CN-XiaoxiaoNeural"
        rate: "+0%"
        volume: "+0%"
        output_audio_format: "wav"
        sample_rate: 16000


  vad: # 语音活动检测 (VAD) 模块
    enabled: true
    module_category: "vad"
    adapter_type: "silero_vad"
    config:
      silero_vad:
        model_repo_path: "models/vad/snakers4/silero-vad"
        model_name: "silero_vad"
        threshold: 0.5
        vad_sample_rate: 16000
        # min_silence_duration_ms: 100 # 这个是VAD内部参数，ChatEngine用下面那个
        min_silence_duration_ms_eos: 1200 # ChatEngine判断语句结束的静默阈值 (ms)
        max_speech_segment_duration_ms: 5000 # 新增：最长语音段持续时间 (ms)，超过则强制ASR
        window_size_samples: 512 # VAD处理窗口大小（样本数），例如 Silero VAD 16kHz下是512
        device: "cpu"

# --- 全局应用设置 ---
global_settings:
  log_level: "INFO" # 应用的全局日志级别 ("DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL")

# --- 提示词激活功能设置 ---
activation_settings:
  enable_prompt_activation: true # 开关：是否启用提示词激活功能
  activation_keywords: ["你好小助手", "启动对话", "你好小爱", "你好助手"] # 激活关键词列表
  activation_timeout_seconds: 30 # 激活后，无交互的超时时间 (秒)
  activation_reply: "你好！很高兴为您服务，请问有什么可以帮您的吗？" # 成功激活后的回复
  deactivation_reply: "再见，本次服务结束，期待下次能继续帮助您。" # 超时或明确指令导致失活时的回复
  prompt_if_not_activated: "请输入激活指令开始对话，例如“你好小助手”。" # (可选) 当未激活时收到非激活指令的提示

# --- WebSocket 服务器配置 ---
websocket_server:
  host: "0.0.0.0"
  port: 8765
  websocket_max_message_size: 2097152 # WebSocket 消息的最大大小 (字节, 例如 2MB，以容纳更大的音频块)
