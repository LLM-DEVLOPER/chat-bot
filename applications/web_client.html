<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebSocket客户端 (VAD与WAV流畅播放优化)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; margin: 0; background-color: #f3f4f6; display: flex; justify-content: center; align-items: center; min-height: 100vh; color: #374151; padding: 1rem;}
        .container { background-color: white; padding: 2rem; border-radius: 0.75rem; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1), 0 4px 6px -2px rgba(0,0,0,0.05); width: 100%; max-width: 500px; }
        .btn { padding: 0.625rem 1.25rem; border-radius: 0.375rem; font-weight: 500; transition: background-color 0.2s ease-in-out, box-shadow 0.2s ease-in-out; display: inline-flex; align-items: center; justify-content: center; cursor: pointer; }
        .btn:focus { outline: 2px solid transparent; outline-offset: 2px; box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.5); }
        .btn-primary { background-color: #3b82f6; color: white; }
        .btn-primary:hover { background-color: #2563eb; }
        .btn-primary:disabled { background-color: #9ca3af; cursor: not-allowed; }
        .btn-secondary { background-color: #6b7280; color: white; }
        .btn-secondary:hover { background-color: #4b5563; }
        .btn-danger { background-color: #ef4444; color: white; }
        .btn-danger:hover { background-color: #dc2626; }
        .input-text { border: 1px solid #d1d5db; padding: 0.625rem; border-radius: 0.375rem; width: 100%; margin-bottom: 1rem; box-shadow: inset 0 1px 2px 0 rgba(0,0,0,0.05); }
        .input-text:focus { border-color: #3b82f6; box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.3); }
        .status, .server-messages, .debug-area { margin-top: 1rem; padding: 0.875rem; border-radius: 0.375rem; font-size: 0.875rem; word-wrap: break-word; }
        .status-vad { font-weight: bold; }
        .status-info { background-color: #eff6ff; color: #3b82f6; border: 1px solid #bfdbfe; }
        .status-success { background-color: #f0fdf4; color: #22c55e; border: 1px solid #bbf7d0; }
        .status-error { background-color: #fef2f2; color: #ef4444; border: 1px solid #fecaca; }
        .hidden { display: none; }
        h1 { font-size: 1.75rem; font-weight: 600; margin-bottom: 1.5rem; text-align: center; color: #111827; }
        label { display: block; margin-bottom: 0.25rem; font-weight: 500; color: #4b5563; }
        .debug-area a { color: #3b82f6; text-decoration: underline; }
        .debug-area a:hover { color: #2563eb; }
    </style>
</head>
<body>
    <div class="container">
        <h1>WebSocket客户端 (VAD与WAV流畅播放优化)</h1>

        <div class="mb-4">
            <label for="wsUrl">WebSocket URL:</label>
            <input type="text" id="wsUrlVad" class="input-text" value="ws://localhost:8766">
            <button id="connectButtonVad" class="btn btn-primary w-full mb-2">连接</button>
            <button id="disconnectButtonVad" class="btn btn-secondary w-full hidden">断开连接</button>
        </div>

        <div class="mb-4">
            <label for="clientSessionIdInput">客户端会话ID (UUID):</label>
            <input type="text" id="clientSessionIdInput" class="input-text" readonly>
            <button id="generateUuidButton" class="btn btn-secondary text-sm py-1 px-2 mb-2">产生新的UUID</button>
        </div>

        <div class="mb-4">
            <label for="textInputVad">发送文本消息:</label>
            <textarea id="textInputVad" class="input-text" rows="2">你好！</textarea>
            <button id="sendTextButtonVad" class="btn btn-primary w-full" disabled>发送文本</button>
        </div>

        <div class="mb-4">
            <label>麦克风控制:</label>
            <div>
                <button id="startRecordButtonVad" class="btn btn-primary" disabled>开始录音 (VAD)</button>
                <button id="stopRecordButtonVad" class="btn btn-danger hidden">停止录音</button>
            </div>
        </div>

        <div id="statusAreaVad" class="status status-info">状态：未连接</div>
        <div id="vadStateDisplay" class="status status-info mt-2">VAD状态: 静默</div>
        <div id="serverMessagesVad" class="server-messages bg-gray-100 border border-gray-200 mt-2 p-2 h-32 overflow-y-auto">服务器文本消息将显示在此...</div>

        <div class="mt-4">
            <label>音频播放状态:</label>
            <div id="audioPlaybackStatus" class="status status-info">播放器: 空闲</div>
            <div id="decodedAudioQueueInfo" class="status status-info mt-1 text-xs">主累积PCM缓冲区时长: 0.00s</div>
        </div>
        <div id="audioDebugArea" class="debug-area bg-yellow-100 border border-yellow-300 mt-2 p-2 hidden">
            <p><strong>完整音频流下载 (拼接原始WAV块):</strong></p>
            <div id="completeStreamDownloadLink"></div>
        </div>
    </div>

    <script>
        const wsUrlInputVad = document.getElementById('wsUrlVad');
        const connectButtonVad = document.getElementById('connectButtonVad');
        const disconnectButtonVad = document.getElementById('disconnectButtonVad');

        const clientSessionIdInput = document.getElementById('clientSessionIdInput');
        const generateUuidButton = document.getElementById('generateUuidButton');

        const textInputVad = document.getElementById('textInputVad');
        const sendTextButtonVad = document.getElementById('sendTextButtonVad');

        const startRecordButtonVad = document.getElementById('startRecordButtonVad');
        const stopRecordButtonVad = document.getElementById('stopRecordButtonVad');
        const statusAreaVad = document.getElementById('statusAreaVad');
        const vadStateDisplay = document.getElementById('vadStateDisplay');
        const serverMessagesVad = document.getElementById('serverMessagesVad');
        const audioPlaybackStatus = document.getElementById('audioPlaybackStatus');
        const decodedAudioQueueInfo = document.getElementById('decodedAudioQueueInfo');
        const audioDebugArea = document.getElementById('audioDebugArea');
        const completeStreamDownloadLinkContainer = document.getElementById('completeStreamDownloadLink');


        let websocketVad = null;
        let micAudioContext = null;
        let mediaStreamVad = null;
        let audioWorkletNodeVad = null;

        let serverPlaybackAudioContext = null;
        let mainAccumulatedPcmData = new Float32Array(0);
        let isServerAudioPlaying = false;
        let currentSourceNode = null;
        let nextChunkPlayTime = 0;

        let accumulatedRawWavBlobs = [];

        const TARGET_AUDIO_SAMPLE_RATE = 16000;
        const SEND_BUFFER_SIZE_SAMPLES = 2048;

        const MIN_PLAYBACK_CHUNK_DURATION_S = 1.0;  // 增加到1.0秒
        const TARGET_PLAYBACK_CHUNK_DURATION_S = 2.5; // 目标播放的大块时长，例如2.5秒

        const MAX_ACCUMULATED_PCM_DURATION_S = 7.0; // 主累积PCM缓冲区最多缓冲7秒
        const PLAYBACK_START_DELAY_S = 0.05; // 50ms 的启动延迟 (可调整)

        const audioProcessorNameVad = 'vad-audio-processor';
        const audioProcessorCodeVad = `
            class VadAudioProcessor extends AudioWorkletProcessor {
                constructor(options) {
                    super();
                    this.inputSampleRate = options.processorOptions.inputSampleRate;
                    this.outputSampleRate = options.processorOptions.outputSampleRate;
                    this.sendBufferSizeSamples = options.processorOptions.sendBufferSizeSamples;
                    this.resampleRatio = this.inputSampleRate / this.outputSampleRate;
                    this.inputBuffer = [];
                    this.resampledBuffer = [];
                    this.vadThreshold = options.processorOptions.vadThreshold || 0.01;
                    this.vadSilenceFramesThreshold = options.processorOptions.vadSilenceFramesThreshold || 10;
                    this.vadSpeechFramesMin = options.processorOptions.vadSpeechFramesMin || 3;
                    this.vadSpeechPaddingFrames = options.processorOptions.vadSpeechPaddingFrames || 5;
                    this.isSpeaking = false;
                    this.silentFramesCount = 0;
                    this.speechFramesCount = 0;
                    this.paddingFramesSent = 0;
                    this.port.onmessage = (event) => {
                        if (event.data === 'stop') { this.flush(); }
                    };
                }
                calculateRMS(audioFrame) {
                    let sumOfSquares = 0;
                    for (let i = 0; i < audioFrame.length; i++) { sumOfSquares += audioFrame[i] * audioFrame[i]; }
                    return Math.sqrt(sumOfSquares / audioFrame.length);
                }
                resample(inputSamples) {
                    const outputSamples = [];
                    for (let i = 0; i < inputSamples.length / this.resampleRatio; i++) {
                        const inputIndexFloat = i * this.resampleRatio;
                        const inputIndexFloor = Math.floor(inputIndexFloat);
                        const inputIndexCeil = Math.ceil(inputIndexFloat);
                        const fraction = inputIndexFloat - inputIndexFloor;
                        let value;
                        if (this.resampleRatio === 1) { value = inputSamples[inputIndexFloor]; }
                        else {
                            if (inputIndexCeil < inputSamples.length) {
                                const val1 = inputSamples[inputIndexFloor]; const val2 = inputSamples[inputIndexCeil];
                                value = val1 + (val2 - val1) * fraction;
                            } else if (inputIndexFloor < inputSamples.length) { value = inputSamples[inputIndexFloor]; }
                            else { break; }
                        }
                        outputSamples.push(value);
                    }
                    return outputSamples;
                }
                flush() {
                    if (this.resampledBuffer.length > 0) {
                        this.port.postMessage({ type: 'audio_data', data: new Float32Array(this.resampledBuffer.slice()) });
                        this.resampledBuffer = [];
                    }
                    this.port.postMessage({ type: 'vad_state', speaking: false, flushing: true });
                }
                process(inputs, outputs, parameters) {
                    const inputChannelData = inputs[0]?.[0];
                    if (!inputChannelData || inputChannelData.length === 0) { return true; }
                    const currentResampledBlock = this.resample(inputChannelData);
                    if (currentResampledBlock.length === 0) return true;
                    const rms = this.calculateRMS(currentResampledBlock);
                    const currentlyDetectedSpeech = rms > this.vadThreshold;
                    if (currentlyDetectedSpeech) {
                        this.speechFramesCount++; this.silentFramesCount = 0;
                        if (this.speechFramesCount >= this.vadSpeechFramesMin && !this.isSpeaking) {
                            this.isSpeaking = true; this.paddingFramesSent = 0;
                            this.port.postMessage({ type: 'vad_state', speaking: true });
                        }
                    } else {
                        this.speechFramesCount = 0;
                        if (this.isSpeaking) {
                            this.silentFramesCount++;
                            if (this.silentFramesCount >= this.vadSilenceFramesThreshold) {
                                this.isSpeaking = false;
                                this.port.postMessage({ type: 'vad_state', speaking: false });
                            }
                        }
                    }
                    if (this.isSpeaking || (this.paddingFramesSent < this.vadSpeechPaddingFrames && !this.isSpeaking && this.silentFramesCount > 0) ) {
                        this.resampledBuffer.push(...currentResampledBlock);
                        if (!this.isSpeaking && this.silentFramesCount > 0) { this.paddingFramesSent++; }
                        while (this.resampledBuffer.length >= this.sendBufferSizeSamples) {
                            const chunkToSend = this.resampledBuffer.splice(0, this.sendBufferSizeSamples);
                            this.port.postMessage({ type: 'audio_data', data: new Float32Array(chunkToSend) });
                        }
                    } else if (this.resampledBuffer.length > 0 && !this.isSpeaking && this.silentFramesCount > 0) {
                         this.flush();
                    }
                    return true;
                }
            }
            registerProcessor('${audioProcessorNameVad}', VadAudioProcessor);
        `;

        function updateStatusVad(message, type = 'info') {
            console.log(`[ClientVAD Status] ${type.toUpperCase()}: ${message}`);
            statusAreaVad.textContent = `状态：${message}`;
            statusAreaVad.className = `status status-${type}`;
        }
        function updateVadStateDisplay(isSpeaking) {
            vadStateDisplay.textContent = `VAD状态: ${isSpeaking ? '侦测到语音' : '静默'}`;
            vadStateDisplay.className = `status ${isSpeaking ? 'status-success' : 'status-info'} mt-2 status-vad`;
        }
        function appendServerMessageVad(message) {
            const p = document.createElement('p');
            const timestamp = new Date().toLocaleTimeString();
            p.innerHTML = `<span class="text-xs text-gray-500">[${timestamp}]</span> ${message}`;
            serverMessagesVad.appendChild(p);
            serverMessagesVad.scrollTop = serverMessagesVad.scrollHeight;
        }
        function updateAudioPlaybackStatus(message) {
            audioPlaybackStatus.textContent = `播放器: ${message}`;
            console.log(`[ClientVAD Playback Status] ${message}`);
        }
        function updateAccumulatedPcmInfo() {
            const duration = mainAccumulatedPcmData.length / TARGET_AUDIO_SAMPLE_RATE;
            decodedAudioQueueInfo.textContent = `主累积PCM缓冲区时长: ${duration.toFixed(2)}s (样本数: ${mainAccumulatedPcmData.length})`;
            console.log(`[ClientVAD Buffer] 主累积PCM: ${mainAccumulatedPcmData.length} 样本, ${duration.toFixed(3)}s`);
        }


        function generateAndSetUuid() {
            const newUuid = self.crypto.randomUUID();
            clientSessionIdInput.value = newUuid;
            localStorage.setItem('clientSessionIdForChatbot', newUuid);
            console.log(`[ClientVAD] 产生并设定新的客户端会话ID: ${newUuid}`);
            return newUuid;
        }

        generateUuidButton.onclick = generateAndSetUuid;

        let currentClientSessionId = localStorage.getItem('clientSessionIdForChatbot');
        if (!currentClientSessionId) {
            currentClientSessionId = generateAndSetUuid();
        } else {
            clientSessionIdInput.value = currentClientSessionId;
            console.log(`[ClientVAD] 从 localStorage 加载会话ID: ${currentClientSessionId}`);
        }

        async function initializeServerPlaybackAudioContext() {
            if (!serverPlaybackAudioContext) {
                try {
                    serverPlaybackAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: TARGET_AUDIO_SAMPLE_RATE
                    });
                    if (serverPlaybackAudioContext.state === 'suspended') {
                        await serverPlaybackAudioContext.resume();
                    }
                    console.log(`[ClientVAD Playback] 服务器音频播放的 AudioContext 已初始化。请求/实际采样率: ${serverPlaybackAudioContext.sampleRate}`);
                    updateAudioPlaybackStatus("已准备");
                } catch (e) {
                    console.error("[ClientVAD Playback] 初始化服务器音频播放的 AudioContext 失败:", e);
                    updateAudioPlaybackStatus(`错误: ${e.message}`);
                    appendServerMessageVad(`错误：无法初始化音频播放器 - ${e.message}`);
                }
            } else if (serverPlaybackAudioContext.state === 'suspended') {
                 await serverPlaybackAudioContext.resume();
                 console.log('[ClientVAD Playback] 服务器音频播放的 AudioContext 已恢复');
            }
        }

        function playNextLargeAudioChunk() {
            if (isServerAudioPlaying) {
                console.debug("[ClientVAD Playback] playNextLarge: 播放器正忙，等待当前块结束。");
                return;
            }

            const accumulatedDuration = mainAccumulatedPcmData.length / TARGET_AUDIO_SAMPLE_RATE;
            // 只有当累积的数据足够一个最小播放块，并且播放器空闲时才开始
            if (mainAccumulatedPcmData.length === 0 || accumulatedDuration < MIN_PLAYBACK_CHUNK_DURATION_S) {
                if (mainAccumulatedPcmData.length === 0) {
                    updateAudioPlaybackStatus("空闲 (主PCM缓冲区为空)");
                } else {
                    updateAudioPlaybackStatus(`正在累积PCM以达到最小缓冲... (当前: ${accumulatedDuration.toFixed(2)}s / 需至少: ${MIN_PLAYBACK_CHUNK_DURATION_S}s)`);
                }
                updateAccumulatedPcmInfo();
                return;
            }

            isServerAudioPlaying = true;

            const samplesForTargetDuration = Math.floor(TARGET_PLAYBACK_CHUNK_DURATION_S * TARGET_AUDIO_SAMPLE_RATE);
            const samplesToPlay = Math.min(mainAccumulatedPcmData.length, samplesForTargetDuration);

            console.log(`[ClientVAD Playback] 准备播放大块。累积样本: ${mainAccumulatedPcmData.length}, 目标播放样本: ${samplesToPlay}, 目标块时长: ${TARGET_PLAYBACK_CHUNK_DURATION_S}s`);

            const pcmChunkToPlay = mainAccumulatedPcmData.slice(0, samplesToPlay);
            mainAccumulatedPcmData = mainAccumulatedPcmData.slice(samplesToPlay);
            updateAccumulatedPcmInfo();

            if (!serverPlaybackAudioContext || pcmChunkToPlay.length === 0) {
                console.warn("[ClientVAD Playback] AudioContext 未就绪或待播放PCM数据为空。");
                isServerAudioPlaying = false;
                if (mainAccumulatedPcmData.length > 0) setTimeout(playNextLargeAudioChunk, 50); // 稍后重试
                return;
            }

            console.log(`[ClientVAD Playback DEBUG] 创建大块 AudioBuffer: 声道=1, 长度=${pcmChunkToPlay.length}, 数据采样率=${TARGET_AUDIO_SAMPLE_RATE}`);
            const audioBufferToPlay = serverPlaybackAudioContext.createBuffer(
                1,
                pcmChunkToPlay.length,
                TARGET_AUDIO_SAMPLE_RATE
            );
            try {
                audioBufferToPlay.getChannelData(0).set(pcmChunkToPlay);
            } catch (e) {
                console.error("[ClientVAD Playback] 设置 AudioBuffer 数据时出错:", e, "PCM数据长度:", pcmChunkToPlay.length);
                isServerAudioPlaying = false;
                updateAudioPlaybackStatus("错误: 设置Buffer数据失败");
                if (mainAccumulatedPcmData.length > 0) setTimeout(playNextLargeAudioChunk, 50);
                return;
            }

            currentSourceNode = serverPlaybackAudioContext.createBufferSource();
            currentSourceNode.buffer = audioBufferToPlay;
            currentSourceNode.connect(serverPlaybackAudioContext.destination);

            currentSourceNode.onended = () => {
                console.log(`[ClientVAD Playback] 大块 AudioBuffer (时长: ${audioBufferToPlay.duration.toFixed(3)}s) 播放结束。AudioContext当前时间: ${serverPlaybackAudioContext.currentTime.toFixed(3)}`);
                isServerAudioPlaying = false;
                currentSourceNode = null;
                if (nextChunkPlayTime < serverPlaybackAudioContext.currentTime - 0.1) {
                    console.warn(`[ClientVAD Playback] onended: nextChunkPlayTime (${nextChunkPlayTime.toFixed(3)}) 远落后于 currentTime (${serverPlaybackAudioContext.currentTime.toFixed(3)})。重置 nextChunkPlayTime。`);
                    nextChunkPlayTime = serverPlaybackAudioContext.currentTime;
                }
                playNextLargeAudioChunk();
            };

            let scheduledPlayTime = nextChunkPlayTime;
            if (scheduledPlayTime < serverPlaybackAudioContext.currentTime) {
                scheduledPlayTime = serverPlaybackAudioContext.currentTime + PLAYBACK_START_DELAY_S;
                console.log(`[ClientVAD Playback] 预定播放时间 (${nextChunkPlayTime.toFixed(3)}s) 已过或太近，调整为 ${scheduledPlayTime.toFixed(3)}s`);
            }

            console.log(`[ClientVAD Playback] 计划在 ${scheduledPlayTime.toFixed(3)}s 开始播放大块 AudioBuffer (时长: ${audioBufferToPlay.duration.toFixed(3)}s)`);
            updateAudioPlaybackStatus(`正在播放 (主缓冲区剩余: ${(mainAccumulatedPcmData.length / TARGET_AUDIO_SAMPLE_RATE).toFixed(2)}s)`);
            try {
                currentSourceNode.start(scheduledPlayTime);
                nextChunkPlayTime = scheduledPlayTime + audioBufferToPlay.duration;
                console.log(`[ClientVAD Playback] 下一个块的预定播放时间更新为: ${nextChunkPlayTime.toFixed(3)}s`);
            } catch (e) {
                console.error("[ClientVAD Playback] 调用 sourceNode.start() 失败:", e);
                isServerAudioPlaying = false;
                updateAudioPlaybackStatus("错误: 启动播放失败");
                nextChunkPlayTime = serverPlaybackAudioContext.currentTime;
                if (mainAccumulatedPcmData.length > 0) setTimeout(playNextLargeAudioChunk, 50);
            }
        }

        function createAndDisplayCompleteStreamDownloadLink() {
            if (accumulatedRawWavBlobs.length === 0) {
                completeStreamDownloadLinkContainer.innerHTML = '<span>没有累积的音频数据可供下载。</span>';
                if (audioDebugArea.classList.contains('hidden')) audioDebugArea.classList.remove('hidden');
                return;
            }
            try {
                const completeBlob = new Blob(accumulatedRawWavBlobs, {type: 'audio/wav'});
                const url = URL.createObjectURL(completeBlob);
                const link = document.createElement('a');
                link.href = url;
                const fileName = `complete_audio_stream_${clientSessionIdInput.value.substring(0,8)}.wav`;
                link.download = fileName;
                link.textContent = `下载完整音频流 (拼接WAV块): ${fileName} (${(completeBlob.size / 1024).toFixed(2)} KB)`;
                link.className = "block mt-1 mb-1 text-blue-600 hover:text-blue-800 underline";

                completeStreamDownloadLinkContainer.innerHTML = '';
                completeStreamDownloadLinkContainer.appendChild(link);
                if (audioDebugArea.classList.contains('hidden')) audioDebugArea.classList.remove('hidden');

                link.onclick = () => {
                    console.log(`[ClientVAD Debug] 用户点击下载完整音频流: ${fileName}`);
                    setTimeout(() => {
                        URL.revokeObjectURL(url);
                        console.log(`[ClientVAD Debug] 已释放完整流的 Blob URL.`);
                    }, 300);
                };
            } catch (e) {
                console.error("[ClientVAD Debug] 创建完整流下载链接失败:", e);
                completeStreamDownloadLinkContainer.textContent = `创建下载链接失败: ${e.message}`;
                if (audioDebugArea.classList.contains('hidden')) audioDebugArea.classList.remove('hidden');
            }
        }


        connectButtonVad.onclick = async () => {
            if (websocketVad && websocketVad.readyState === WebSocket.OPEN) {
                updateStatusVad('已连接，无需重复连接。', 'info');
                return;
            }
            await initializeServerPlaybackAudioContext();
            connectWebSocketVad();
        };

        disconnectButtonVad.onclick = () => {
            if (websocketVad) {
                websocketVad.close();
            }
            if (currentSourceNode) {
                currentSourceNode.onended = null;
                try { currentSourceNode.stop(); } catch(e) { console.warn("停止当前音频源时出错:", e); }
                currentSourceNode = null;
            }
            mainAccumulatedPcmData = new Float32Array(0);
            isServerAudioPlaying = false;
            nextChunkPlayTime = 0;
            accumulatedRawWavBlobs = [];
            updateAccumulatedPcmInfo();
            updateAudioPlaybackStatus("已停止 (断开连接)");
            audioDebugArea.classList.add('hidden');
        };

        function connectWebSocketVad() {
            const wsUrl = wsUrlInputVad.value;
            updateStatusVad('正在连接...', 'info');
            console.log(`[ClientVAD] 尝试连接到: ${wsUrl}`);

            accumulatedRawWavBlobs = [];
            mainAccumulatedPcmData = new Float32Array(0);
            isServerAudioPlaying = false;
            if (serverPlaybackAudioContext) {
                nextChunkPlayTime = serverPlaybackAudioContext.currentTime;
            } else {
                nextChunkPlayTime = 0;
            }
            updateAccumulatedPcmInfo();
            completeStreamDownloadLinkContainer.innerHTML = '';
            audioDebugArea.classList.add('hidden');


            websocketVad = new WebSocket(wsUrl);
            websocketVad.binaryType = "arraybuffer";

            websocketVad.onopen = () => {
                updateStatusVad('已连接', 'success');
                appendServerMessageVad('成功连接到服务器。');
                connectButtonVad.classList.add('hidden');
                disconnectButtonVad.classList.remove('hidden');
                enableControlsOnConnectVad();

                const initMessage = {
                    type: "init_session",
                    session_id: clientSessionIdInput.value,
                    config: { client_type: "web_vad_client_v8_wav_merged_play_optimized" }
                };
                websocketVad.send(JSON.stringify(initMessage));
                console.log(`[ClientVAD] WebSocket 打开，已发送初始化消息: ${JSON.stringify(initMessage)}`);
                appendServerMessageVad(`已发送会话初始化请求 (ID: ${clientSessionIdInput.value})。`);

                if (serverPlaybackAudioContext) {
                    nextChunkPlayTime = serverPlaybackAudioContext.currentTime;
                    console.log(`[ClientVAD Playback] WebSocket连接成功，重置nextChunkPlayTime: ${nextChunkPlayTime.toFixed(3)}s`);
                }
            };

            websocketVad.onmessage = async (event) => {
                if (event.data instanceof ArrayBuffer) {
                    // updateStatusVad('正在接收并解码WAV音频...', 'info'); // 这条日志可能太频繁，先注释
                    const receivedArrayBuffer = event.data;
                    const receivedByteLength = receivedArrayBuffer.byteLength;
                    console.log(`[ClientVAD] 收到 ArrayBuffer (应为WAV) 音频数据，长度: ${receivedByteLength} 字节`);

                    if (receivedByteLength > 0) {
                        accumulatedRawWavBlobs.push(new Blob([receivedArrayBuffer.slice(0)], {type: 'audio/wav'}));
                    }

                    if (!serverPlaybackAudioContext) {
                        await initializeServerPlaybackAudioContext();
                        if (!serverPlaybackAudioContext) {
                             appendServerMessageVad("错误：无法播放收到的音频，音频播放器初始化失败。");
                             return;
                        }
                        nextChunkPlayTime = serverPlaybackAudioContext.currentTime;
                        console.log(`[ClientVAD Playback] AudioContext 首次初始化，设置 nextChunkPlayTime: ${nextChunkPlayTime.toFixed(3)}s`);
                    }

                    if (receivedByteLength === 0) { console.log("[ClientVAD] 收到空音频数据块，忽略。"); return; }

                    try {
                        const dataCopy = receivedArrayBuffer.slice(0);
                        const decodedAudioBuffer = await serverPlaybackAudioContext.decodeAudioData(dataCopy);
                        console.log(`[ClientVAD Playback] WAV块解码成功。采样率: ${decodedAudioBuffer.sampleRate}, 时长: ${decodedAudioBuffer.duration.toFixed(3)}s, 声道数: ${decodedAudioBuffer.numberOfChannels}`);

                        if (decodedAudioBuffer.sampleRate !== TARGET_AUDIO_SAMPLE_RATE) {
                             console.warn(`[ClientVAD Playback] 警告: 解码后的音频采样率 (${decodedAudioBuffer.sampleRate}Hz) 与期望的播放采样率 (${TARGET_AUDIO_SAMPLE_RATE}Hz) 不符。`);
                        }

                        const pcmData = decodedAudioBuffer.getChannelData(0);

                        const currentAccumulatedDuration = mainAccumulatedPcmData.length / TARGET_AUDIO_SAMPLE_RATE;
                        if (currentAccumulatedDuration + pcmData.length / TARGET_AUDIO_SAMPLE_RATE > MAX_ACCUMULATED_PCM_DURATION_S) {
                            console.warn(`[ClientVAD Buffer] 主累积PCM缓冲区将超出最大限制 (${MAX_ACCUMULATED_PCM_DURATION_S}s)。`);
                            const requiredSamplesForMax = Math.floor(MAX_ACCUMULATED_PCM_DURATION_S * TARGET_AUDIO_SAMPLE_RATE);
                            const samplesToKeepFromOld = Math.max(0, requiredSamplesForMax - pcmData.length);
                            if (samplesToKeepFromOld < mainAccumulatedPcmData.length) {
                                console.log(`[ClientVAD Buffer] 截断旧的PCM数据以腾出空间。保留旧数据样本数: ${samplesToKeepFromOld}`);
                                mainAccumulatedPcmData = mainAccumulatedPcmData.slice(mainAccumulatedPcmData.length - samplesToKeepFromOld);
                            } else if (pcmData.length > requiredSamplesForMax) {
                                mainAccumulatedPcmData = pcmData.slice(pcmData.length - requiredSamplesForMax);
                                console.log(`[ClientVAD Buffer] 新PCM块过大，截断新块。`);
                            }
                        }

                        const newAccumulatedPcmData = new Float32Array(mainAccumulatedPcmData.length + pcmData.length);
                        newAccumulatedPcmData.set(mainAccumulatedPcmData);
                        newAccumulatedPcmData.set(pcmData, mainAccumulatedPcmData.length);
                        mainAccumulatedPcmData = newAccumulatedPcmData;
                        updateAccumulatedPcmInfo();

                        playNextLargeAudioChunk();
                    } catch (e) {
                        const errMsg = `错误：解码服务器发送的WAV数据失败 - ${e.message}`;
                        console.error("[ClientVAD Playback] " + errMsg, e);
                        appendServerMessageVad(errMsg);
                        updateStatusVad('WAV数据解码错误', 'error');
                    }

                } else if (typeof event.data === 'string') {
                    console.log(`[ClientVAD] 收到文本消息: ${event.data}`);
                    try {
                        const jsonData = JSON.parse(event.data);
                        if (jsonData.type === "session_established") {
                            updateStatusVad(`会话已建立 (ID: ${jsonData.session_id})`, 'success');
                            appendServerMessageVad(`服务器确认会话: ${jsonData.session_id} - ${jsonData.message}`);
                        } else if (jsonData.type === "text_response") {
                            appendServerMessageVad(`服务器: ${jsonData.content}`);
                        } else if (jsonData.type === "audio_stream_end") {
                            updateStatusVad(jsonData.message || '音频流结束', 'success');
                            appendServerMessageVad(`服务器: ${jsonData.message || '音频流结束'}`);

                            if (accumulatedRawWavBlobs.length > 0) {
                                createAndDisplayCompleteStreamDownloadLink();
                            } else {
                                console.log("[ClientVAD] 音频流结束，但没有累积的WAV数据可供下载。");
                                completeStreamDownloadLinkContainer.innerHTML = '<span>没有可下载的音频数据。</span>';
                                if (audioDebugArea.classList.contains('hidden')) audioDebugArea.classList.remove('hidden');
                            }
                            // accumulatedRawWavBlobs = []; // 清理，为下一个流做准备

                            if (mainAccumulatedPcmData.length > 0 && !isServerAudioPlaying) {
                                console.log("[ClientVAD Playback] 收到 audio_stream_end，尝试播放主累积缓冲区中剩余音频。");
                                playNextLargeAudioChunk();
                            } else if (mainAccumulatedPcmData.length === 0 && !isServerAudioPlaying) {
                                updateAudioPlaybackStatus("空闲 (流结束)");
                            }
                        } else if (jsonData.type === "error") {
                            updateStatusVad(`服务器错误: ${jsonData.message}`, 'error');
                            appendServerMessageVad(`服务器错误: ${jsonData.message}`);
                        } else if (jsonData.type === "info") {
                            updateStatusVad(`服务器信息: ${jsonData.content || jsonData.message}`, 'info');
                            appendServerMessageVad(`服务器信息: ${jsonData.content || jsonData.message}`);
                        } else {
                             appendServerMessageVad(`服务器原始JSON: ${event.data}`);
                        }
                    } catch (e) {
                        appendServerMessageVad(`服务器原始文本: ${event.data}`);
                    }
                }
            };

            websocketVad.onerror = (error) => {
                console.error('[ClientVAD] WebSocket错误:', error);
                updateStatusVad('连接错误，请检查URL或服务器状态。', 'error');
                appendServerMessageVad('WebSocket 连接发生错误。');
                disableControlsOnDisconnectVad();
            };

            websocketVad.onclose = (event) => {
                console.log(`[ClientVAD] 连接已关闭。代码: ${event.code}, 原因: "${event.reason}"`);
                updateStatusVad(`已断开连接 (代码: ${event.code})`, 'info');
                appendServerMessageVad(`与服务器断开连接。代码: ${event.code}`);
                websocketVad = null;
                disableControlsOnDisconnectVad();
                stopRecordingVad(false);

                if (currentSourceNode) {
                    currentSourceNode.onended = null;
                    try { currentSourceNode.stop(); } catch(e) { console.warn("停止当前音频源时出错:", e); }
                    currentSourceNode = null;
                }
                mainAccumulatedPcmData = new Float32Array(0);
                isServerAudioPlaying = false;
                nextChunkPlayTime = 0;
                accumulatedRawWavBlobs = [];
                updateAccumulatedPcmInfo();
                updateAudioPlaybackStatus("已停止 (连接关闭)");
                audioDebugArea.classList.add('hidden');
            };
        }

        function enableControlsOnConnectVad() {
            sendTextButtonVad.disabled = false;
            startRecordButtonVad.disabled = false;
        }

        function disableControlsOnDisconnectVad() {
            sendTextButtonVad.disabled = true;
            startRecordButtonVad.disabled = true;
            stopRecordButtonVad.classList.add('hidden');
            startRecordButtonVad.classList.remove('hidden');
            connectButtonVad.classList.remove('hidden');
            disconnectButtonVad.classList.add('hidden');
        }

        sendTextButtonVad.onclick = () => {
            if (websocketVad && websocketVad.readyState === WebSocket.OPEN) {
                const text = textInputVad.value;
                if (text.trim()) {
                    const message = JSON.stringify({type: "text_input_from_client", content: text});
                    websocketVad.send(message);
                    updateStatusVad(`已发送文本: "${text.substring(0,30)}..."`, 'info');
                    appendServerMessageVad(`我: ${text}`);
                    console.log(`[ClientVAD] 已发送: ${message}`);
                } else {
                    updateStatusVad('发送的文本不能为空', 'error');
                }
            } else {
                updateStatusVad('WebSocket未连接', 'error');
            }
        };

        startRecordButtonVad.onclick = async () => {
            if (!websocketVad || websocketVad.readyState !== WebSocket.OPEN) {
                updateStatusVad('WebSocket未连接，请先连接', 'error');
                return;
            }
            try {
                if (!micAudioContext) {
                     micAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                     console.log(`[ClientVAD Mic] 麦克风 AudioContext已初始化，原始采样率: ${micAudioContext.sampleRate}`);
                }
                if (micAudioContext.state === 'suspended') { await micAudioContext.resume(); }

                mediaStreamVad = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });

                const actualInputSampleRate = micAudioContext.sampleRate;
                console.log(`[ClientVAD Mic] 麦克风已获取。AudioContext 采样率: ${actualInputSampleRate}Hz (将重采样到 ${TARGET_AUDIO_SAMPLE_RATE}Hz)`);
                updateStatusVad('麦克风已授权，正在录音 (VAD激活时发送)...', 'success');
                appendServerMessageVad('开始录音，VAD将控制音频发送...');
                startRecordButtonVad.classList.add('hidden');
                stopRecordButtonVad.classList.remove('hidden');
                updateVadStateDisplay(false);

                const audioWorkletBlob = new Blob([audioProcessorCodeVad], { type: 'application/javascript' });
                const audioWorkletUrl = URL.createObjectURL(audioWorkletBlob);

                await micAudioContext.audioWorklet.addModule(audioWorkletUrl);
                console.log('[ClientVAD AudioWorklet] 模块已添加。');

                const microphoneSource = micAudioContext.createMediaStreamSource(mediaStreamVad);
                audioWorkletNodeVad = new AudioWorkletNode(micAudioContext, audioProcessorNameVad, {
                    processorOptions: {
                        inputSampleRate: actualInputSampleRate,
                        outputSampleRate: TARGET_AUDIO_SAMPLE_RATE,
                        sendBufferSizeSamples: SEND_BUFFER_SIZE_SAMPLES,
                        vadThreshold: 0.01,
                        vadSilenceFramesThreshold: 15,
                        vadSpeechFramesMin: 3,
                        vadSpeechPaddingFrames: 8
                    }
                });

                audioWorkletNodeVad.port.onmessage = (event) => {
                    if (event.data.type === 'audio_data') {
                        const pcmFloat32 = event.data.data;
                        const pcmInt16 = new Int16Array(pcmFloat32.length);
                        for (let i = 0; i < pcmFloat32.length; i++) {
                            pcmInt16[i] = Math.max(-32768, Math.min(32767, Math.round(pcmFloat32[i] * 32767.0)));
                        }
                        if (websocketVad && websocketVad.readyState === WebSocket.OPEN) {
                            websocketVad.send(pcmInt16.buffer);
                        }
                    } else if (event.data.type === 'vad_state') {
                        updateVadStateDisplay(event.data.speaking);
                         if (event.data.flushing) console.log('[ClientVAD] Worklet正在刷新缓冲区。');
                    }
                };
                microphoneSource.connect(audioWorkletNodeVad);

            } catch (err) {
                console.error('[ClientVAD Mic] 麦克风访问或AudioWorklet设定失败:', err);
                updateStatusVad(`麦克风错误: ${err.name} - ${err.message}`, 'error');
                appendServerMessageVad(`麦克风错误: ${err.message}`);
                stopRecordingVad(false);
            }
        };

        stopRecordButtonVad.onclick = () => {
            stopRecordingVad(true);
            updateStatusVad('录音已停止', 'info');
            appendServerMessageVad('录音已停止。');
        };

        function stopRecordingVad(sendEndSignal = true) {
            console.log('[ClientVAD Mic] 尝试停止录音...');
            if (mediaStreamVad) {
                mediaStreamVad.getTracks().forEach(track => track.stop());
                mediaStreamVad = null;
                console.log('[ClientVAD Mic] MediaStream轨道已停止。');
            }
            if (audioWorkletNodeVad) {
                audioWorkletNodeVad.port.postMessage('stop');
                setTimeout(() => {
                    if (audioWorkletNodeVad) {
                       audioWorkletNodeVad.disconnect();
                       audioWorkletNodeVad = null;
                       console.log('[ClientVAD AudioWorklet] Node已断开连接。');
                    }
                }, 100);
            }

            startRecordButtonVad.classList.remove('hidden');
            stopRecordButtonVad.classList.add('hidden');
            updateVadStateDisplay(false);

            if (sendEndSignal && websocketVad && websocketVad.readyState === WebSocket.OPEN) {
                const message = JSON.stringify({type: "audio_stream_end_signal"});
                websocketVad.send(message);
                console.log(`[ClientVAD] 已发送 (audio_stream_end_signal): ${message}`);
            }
        }

        disableControlsOnDisconnectVad();

    </script>
</body>
</html>
